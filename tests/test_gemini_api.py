#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯• Gemini API è½¬å‘æœåŠ¡è¿æ¥
"""

import sys
import os
import io

# è®¾ç½®UTF-8ç¼–ç 
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from modules.ai_integration.api_providers.openai_provider import OpenAIProvider
from modules.ai_integration.api_providers.base_provider import ProviderConfig, ChatMessage

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("=" * 60)
    print("ğŸ” å¼€å§‹æµ‹è¯• Gemini API è½¬å‘æœåŠ¡è¿æ¥...")
    print("=" * 60)

    # é…ç½®ä¿¡æ¯
    config = ProviderConfig(
        api_key="UFXLzCFM2BtvfvAc1ZC5zRkJLPJKvFlKeBKYfI5evJNqMO7t",
        base_url="https://api.kkyyxx.xyz//v1",
        model="gemini-2.5-pro",
        temperature=0.7,
        max_tokens=1000,
        timeout=30
    )

    print(f"\nğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - Base URL: {config.base_url}")
    print(f"  - Model: {config.model}")
    print(f"  - API Key: {config.api_key[:20]}...")
    print(f"  - Temperature: {config.temperature}")
    print(f"  - Max Tokens: {config.max_tokens}")

    # åˆ›å»ºProvider
    provider = OpenAIProvider(config)

    # æµ‹è¯•1: è¿æ¥éªŒè¯
    print("\n" + "=" * 60)
    print("ğŸ“¡ æµ‹è¯•1: APIè¿æ¥éªŒè¯")
    print("=" * 60)

    try:
        is_valid, message = provider.validate_connection()
        if is_valid:
            print(f"âœ… è¿æ¥æˆåŠŸ: {message}")
        else:
            print(f"âŒ è¿æ¥å¤±è´¥: {message}")
            return False
    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False

    # æµ‹è¯•2: ç®€å•å¯¹è¯
    print("\n" + "=" * 60)
    print("ğŸ’¬ æµ‹è¯•2: åŸºç¡€å¯¹è¯åŠŸèƒ½")
    print("=" * 60)

    test_messages = [
        ChatMessage(role="user", content="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±")
    ]

    try:
        print(f"\nå‘é€æ¶ˆæ¯: {test_messages[0].content}")
        response = provider.send_message(test_messages)

        print(f"\nâœ… æ”¶åˆ°å“åº”:")
        print(f"  å†…å®¹: {response.content[:200]}..." if len(response.content) > 200 else f"  å†…å®¹: {response.content}")
        print(f"  Tokens: {response.usage.get('total_tokens', 'N/A')}")
        print(f"  æ¨¡å‹: {response.model}")

    except Exception as e:
        print(f"âŒ å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    # æµ‹è¯•3: æµå¼å“åº”
    print("\n" + "=" * 60)
    print("ğŸŒŠ æµ‹è¯•3: æµå¼å“åº”åŠŸèƒ½")
    print("=" * 60)

    stream_messages = [
        ChatMessage(role="user", content="ä»1æ•°åˆ°10")
    ]

    try:
        print(f"\nå‘é€æµå¼è¯·æ±‚: {stream_messages[0].content}")
        print("æ¥æ”¶ä¸­: ", end="", flush=True)

        full_response = ""
        for chunk in provider.stream_message(stream_messages):
            print(chunk, end="", flush=True)
            full_response += chunk

        print(f"\n\nâœ… æµå¼å“åº”å®Œæˆ")
        print(f"  å®Œæ•´å†…å®¹: {full_response}")

    except Exception as e:
        print(f"\nâŒ æµå¼æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

    # æµ‹è¯•4: å‚æ•°æµ‹è¯•ï¼ˆé€šè¿‡ä¸åŒconfigå®ä¾‹ï¼‰
    print("\n" + "=" * 60)
    print("âš™ï¸ æµ‹è¯•4: å‚æ•°å…¼å®¹æ€§æµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•ä½æ¸©åº¦
    print(f"\næµ‹è¯•ä½æ¸©åº¦ (0.3):")
    try:
        low_temp_config = ProviderConfig(
            api_key=config.api_key,
            base_url=config.base_url,
            model=config.model,
            temperature=0.3,
            max_tokens=50
        )
        low_temp_provider = OpenAIProvider(low_temp_config)
        response = low_temp_provider.send_message([ChatMessage(role="user", content="è¯´ä¸ªæ•°å­—")])
        print(f"  âœ… ä½æ¸©åº¦ - æˆåŠŸ: {response.content[:50]}")
    except Exception as e:
        print(f"  âš ï¸ ä½æ¸©åº¦ - å¤±è´¥: {str(e)[:100]}")

    # æµ‹è¯•é«˜æ¸©åº¦
    print(f"\næµ‹è¯•é«˜æ¸©åº¦ (0.9):")
    try:
        high_temp_config = ProviderConfig(
            api_key=config.api_key,
            base_url=config.base_url,
            model=config.model,
            temperature=0.9,
            max_tokens=50
        )
        high_temp_provider = OpenAIProvider(high_temp_config)
        response = high_temp_provider.send_message([ChatMessage(role="user", content="è¯´ä¸ªæ•°å­—")])
        print(f"  âœ… é«˜æ¸©åº¦ - æˆåŠŸ: {response.content[:50]}")
    except Exception as e:
        print(f"  âš ï¸ é«˜æ¸©åº¦ - å¤±è´¥: {str(e)[:100]}")

    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼APIå¯ç”¨")
    print("=" * 60)
    return True

if __name__ == "__main__":
    success = test_api_connection()
    sys.exit(0 if success else 1)
