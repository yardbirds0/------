# -*- coding: utf-8 -*-
"""
è¯Šæ–­æµå¼å“åº”é—®é¢˜çš„æµ‹è¯•è„šæœ¬
è¿½è¸ªæ•´ä¸ªæµç¨‹å¹¶è¾“å‡ºè¯¦ç»†æ—¥å¿—
"""

import sys
import logging
from pathlib import Path

# è®¾ç½®é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# é…ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    from modules.ai_integration.api_providers import OpenAIProvider
    from modules.ai_integration.api_providers.base_provider import ProviderConfig

    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 1: æµ‹è¯• API è¿æ¥")
    logger.info("=" * 60)

    config = ProviderConfig(
        api_key="UFXLzCFM2BtvfvAc1ZC5zRkJLPJKvFlKeBKYfI5evJNqMO7t",
        base_url="https://api.kkyyxx.xyz/v1",
        model="gemini-2.5-pro",
        temperature=0.3,
        max_tokens=2000,
        timeout=30
    )

    logger.info(f"é…ç½®ä¿¡æ¯:")
    logger.info(f"  - API Key: {config.api_key[:20]}...")
    logger.info(f"  - Base URL: {config.base_url}")
    logger.info(f"  - Model: {config.model}")

    provider = OpenAIProvider(config)

    logger.info("\næ­£åœ¨éªŒè¯è¿æ¥...")
    success, message = provider.validate_connection()

    if success:
        logger.info(f"âœ… {message}")
        return provider
    else:
        logger.error(f"âŒ {message}")
        return None


def test_stream_response(provider):
    """æµ‹è¯•æµå¼å“åº”"""
    from modules.ai_integration.api_providers.base_provider import ChatMessage

    logger.info("\n" + "=" * 60)
    logger.info("æ­¥éª¤ 2: æµ‹è¯•æµå¼å“åº”")
    logger.info("=" * 60)

    messages = [
        ChatMessage(role='user', content='Say hello in 1-2 sentences')
    ]

    logger.info(f"\nå‘é€æµ‹è¯•æ¶ˆæ¯: {messages[0].content}")
    logger.info("æ­£åœ¨ç­‰å¾…æµå¼å“åº”...\n")

    try:
        chunk_count = 0
        full_response = ""

        stream_iterator = provider.stream_message(
            messages,
            system_prompt="You are a friendly assistant."
        )

        logger.info("ğŸ“¡ å¼€å§‹æ¥æ”¶æµå¼å“åº”:")
        logger.info("-" * 60)

        for chunk in stream_iterator:
            chunk_count += 1
            full_response += chunk

            # æ˜¾ç¤ºæ¯ä¸ªchunkï¼ˆå¸¦åºå·ï¼‰
            print(f"[Chunk {chunk_count:03d}] {repr(chunk)}", flush=True)

        logger.info("-" * 60)
        logger.info(f"\nâœ… æµå¼å“åº”å®Œæˆ:")
        logger.info(f"  - æ€»chunkæ•°: {chunk_count}")
        logger.info(f"  - å“åº”é•¿åº¦: {len(full_response)} å­—ç¬¦")
        logger.info(f"\nå®Œæ•´å“åº”:\n{full_response}")

        return True

    except Exception as e:
        logger.error(f"\nâŒ æµå¼å“åº”å¤±è´¥:")
        logger.error(f"  - å¼‚å¸¸ç±»å‹: {type(e).__name__}")
        logger.error(f"  - é”™è¯¯ä¿¡æ¯: {str(e)}")
        logger.exception("è¯¦ç»†å †æ ˆ:")
        return False


def test_streaming_handler():
    """æµ‹è¯•StreamingHandler"""
    from PySide6.QtWidgets import QApplication
    from PySide6.QtCore import QTimer
    from modules.ai_integration import StreamingHandler, ChatManager
    from modules.ai_integration.api_providers import OpenAIProvider
    from modules.ai_integration.api_providers.base_provider import ProviderConfig, ChatMessage

    logger.info("\n" + "=" * 60)
    logger.info("æ­¥éª¤ 3: æµ‹è¯• StreamingHandler + Qtä¿¡å·")
    logger.info("=" * 60)

    app = QApplication.instance() or QApplication(sys.argv)

    # é…ç½®
    config = ProviderConfig(
        api_key="UFXLzCFM2BtvfvAc1ZC5zRkJLPJKvFlKeBKYfI5evJNqMO7t",
        base_url="https://api.kkyyxx.xyz/v1",
        model="gemini-2.5-pro",
        temperature=0.3,
        max_tokens=2000,
        timeout=30
    )

    provider = OpenAIProvider(config)
    streaming_handler = StreamingHandler(provider)
    chat_manager = ChatManager()

    # æµ‹è¯•çŠ¶æ€
    test_state = {
        'started': False,
        'chunks': [],
        'finished': False,
        'error': None
    }

    # è¿æ¥ä¿¡å·
    def on_started():
        test_state['started'] = True
        logger.info("ğŸ”” ä¿¡å·: stream_started")

    def on_chunk(chunk):
        test_state['chunks'].append(chunk)
        chunk_num = len(test_state['chunks'])
        logger.info(f"ğŸ”” ä¿¡å·: chunk_received #{chunk_num}: {repr(chunk[:50])}")

    def on_finished(response):
        test_state['finished'] = True
        logger.info(f"ğŸ”” ä¿¡å·: stream_finished (é•¿åº¦: {len(response)} å­—ç¬¦)")

        # éªŒè¯ç»“æœ
        logger.info("\n" + "=" * 60)
        logger.info("æµ‹è¯•ç»“æœ:")
        logger.info("=" * 60)
        logger.info(f"âœ… stream_started: {test_state['started']}")
        logger.info(f"âœ… chunks received: {len(test_state['chunks'])}")
        logger.info(f"âœ… stream_finished: {test_state['finished']}")
        logger.info(f"âœ… no errors: {test_state['error'] is None}")

        # 3ç§’åé€€å‡º
        QTimer.singleShot(3000, app.quit)

    def on_error(error):
        test_state['error'] = error
        logger.error(f"ğŸ”” ä¿¡å·: stream_error: {error}")
        QTimer.singleShot(1000, app.quit)

    streaming_handler.stream_started.connect(on_started)
    streaming_handler.chunk_received.connect(on_chunk)
    streaming_handler.stream_finished.connect(on_finished)
    streaming_handler.stream_error.connect(on_error)

    # å‘é€æ¶ˆæ¯
    user_msg = "Say hello in 1-2 sentences"
    chat_manager.add_message('user', user_msg)
    messages = chat_manager.get_context_messages()

    logger.info(f"\nå‘é€æµ‹è¯•æ¶ˆæ¯: {user_msg}")
    streaming_handler.start_stream(messages, system_prompt="You are a friendly assistant.")

    # 30ç§’è¶…æ—¶ä¿æŠ¤
    QTimer.singleShot(30000, lambda: [
        logger.error("â±ï¸ è¶…æ—¶: æµ‹è¯•è¶…è¿‡30ç§’"),
        app.quit()
    ])

    logger.info("ç­‰å¾…Qtäº‹ä»¶å¾ªç¯...\n")
    sys.exit(app.exec())


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    logger.info("\n" + "=" * 70)
    logger.info("AI Streaming Diagnosis Tool")
    logger.info("=" * 70)

    # æµ‹è¯•1: APIè¿æ¥
    provider = test_api_connection()
    if not provider:
        logger.error("\nâŒ APIè¿æ¥å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        return

    # æµ‹è¯•2: åŸå§‹æµå¼å“åº”
    if not test_stream_response(provider):
        logger.error("\nâŒ æµå¼å“åº”æµ‹è¯•å¤±è´¥ï¼Œåœæ­¢åç»­æµ‹è¯•")
        return

    # æµ‹è¯•3: StreamingHandler + Qt
    logger.info("\nå‡†å¤‡æµ‹è¯• StreamingHandler...")
    input("\næŒ‰å›è½¦é”®ç»§ç»­æµ‹è¯•StreamingHandlerï¼ˆéœ€è¦Qtçª—å£ï¼‰...")
    test_streaming_handler()


if __name__ == '__main__':
    main()
