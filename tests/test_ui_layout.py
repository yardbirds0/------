# -*- coding: utf-8 -*-
"""
Modern UI Test Script
æµ‹è¯•ç°ä»£åŒ–UIç•Œé¢å®ç°
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from PySide6.QtWidgets import QApplication
from PySide6.QtCore import QTimer
from controllers.chat_controller import ChatController
from modules.ai_integration import ProviderConfig
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_modern_ui():
    """æµ‹è¯•ç°ä»£åŒ–UIç•Œé¢"""
    app = QApplication(sys.argv)

    # åˆ›å»ºæ§åˆ¶å™¨
    controller = ChatController()

    # é…ç½®AIæœåŠ¡ï¼ˆä½¿ç”¨è™šæ‹Ÿé…ç½®è¿›è¡ŒUIæµ‹è¯•ï¼‰
    config = ProviderConfig(
        base_url="https://api.openai.com/v1",  # è™šæ‹ŸURLï¼Œä»…ç”¨äºUIæµ‹è¯•
        api_key="test-key-12345",  # è™šæ‹Ÿå¯†é’¥
        model="gpt-3.5-turbo",
        temperature=0.3,
        max_tokens=2000,
        top_p=1.0,
        frequency_penalty=0.0,
        presence_penalty=0.0
    )

    try:
        # åˆå§‹åŒ–æ§åˆ¶å™¨
        controller.initialize(config)
        logger.info("âœ… æ§åˆ¶å™¨åˆå§‹åŒ–æˆåŠŸ")

        # æ˜¾ç¤ºå¯¹è¯çª—å£
        controller.show_chat_window()
        logger.info("âœ… ç°ä»£åŒ–å¯¹è¯çª—å£æ˜¾ç¤ºæˆåŠŸ")

        # è·å–ç»„ä»¶å¼•ç”¨è¿›è¡Œæ£€æŸ¥
        if controller.chat_window:
            window = controller.chat_window

            # æ£€æŸ¥å‚æ•°é¢æ¿
            param_panel = window.get_parameter_panel()
            if param_panel:
                logger.info("âœ… ç°ä»£åŒ–å‚æ•°é…ç½®é¢æ¿å·²åŠ è½½")

                # æµ‹è¯•å‚æ•°è®¾ç½®
                test_params = {
                    'temperature': 0.5,
                    'max_tokens': 1500,
                    'top_p': 0.9,
                    'frequency_penalty': 0.1,
                    'presence_penalty': 0.2,
                    'stream_output': True,
                    'system_prompt': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹'
                }
                param_panel.set_parameters(test_params)
                logger.info(f"âœ… è®¾ç½®æµ‹è¯•å‚æ•°: {test_params}")

                # è·å–å‚æ•°éªŒè¯æ˜¯å¦æ­£ç¡®è®¾ç½®
                current_params = param_panel.get_parameters()
                logger.info(f"âœ… å½“å‰å‚æ•°å€¼: {current_params}")

                # æ£€æŸ¥ä¸­æ–‡æ ‡ç­¾
                logger.info("ğŸ” æ£€æŸ¥ä¸­æ–‡å‚æ•°è¯´æ˜:")
                logger.info("  - æ¸©åº¦ (Temperature): æ§åˆ¶å›å¤çš„åˆ›æ„æ€§å’Œéšæœºæ€§")
                logger.info("  - æ ¸é‡‡æ · (Top P): æ§åˆ¶è¯æ±‡é€‰æ‹©çš„å¤šæ ·æ€§")
                logger.info("  - æœ€å¤§ä»¤ç‰Œæ•° (Max Tokens): æ§åˆ¶å›å¤çš„æœ€å¤§é•¿åº¦")
                logger.info("  - é¢‘ç‡æƒ©ç½š (Frequency Penalty): å‡å°‘é‡å¤ä½¿ç”¨ç›¸åŒè¯æ±‡")
                logger.info("  - å­˜åœ¨æƒ©ç½š (Presence Penalty): é¼“åŠ±è°ˆè®ºæ–°è¯é¢˜")
                logger.info("  - æµå¼è¾“å‡º (Stream Output): å®æ—¶æ˜¾ç¤ºAIå“åº”")

            else:
                logger.error("âŒ æ— æ³•è·å–å‚æ•°é…ç½®é¢æ¿")

            # æ£€æŸ¥è°ƒè¯•æŸ¥çœ‹å™¨
            debug_viewer = window.get_debug_viewer()
            if debug_viewer:
                logger.info("âœ… ç°ä»£åŒ–è°ƒè¯•ä¿¡æ¯æŸ¥çœ‹å™¨å·²åŠ è½½")

                # æµ‹è¯•è°ƒè¯•æ—¥å¿—
                test_request = {
                    'model': 'gpt-3.5-turbo',
                    'messages': [
                        {'role': 'user', 'content': 'æµ‹è¯•æ¶ˆæ¯'}
                    ],
                    'temperature': 0.5,
                    'max_tokens': 1500
                }

                test_response = {
                    'content': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å“åº”',
                    'finish_reason': 'stop',
                    'model': 'gpt-3.5-turbo'
                }

                test_tokens = {
                    'prompt_tokens': 10,
                    'completion_tokens': 15,
                    'total_tokens': 25
                }

                debug_viewer.log_api_call(
                    request_data=test_request,
                    response_data=test_response,
                    elapsed_time=1.23,
                    token_count=test_tokens
                )
                logger.info("âœ… æµ‹è¯•è°ƒè¯•ä¿¡æ¯è®°å½•æˆåŠŸ")

                # æµ‹è¯•æŠ˜å /å±•å¼€åŠŸèƒ½
                debug_viewer.toggle_expand()
                logger.info("âœ… è°ƒè¯•é¢æ¿æŠ˜å /å±•å¼€åŠŸèƒ½æ­£å¸¸")

            else:
                logger.error("âŒ æ— æ³•è·å–è°ƒè¯•ä¿¡æ¯æŸ¥çœ‹å™¨")

            # æ£€æŸ¥UIæ ·å¼
            logger.info("\nğŸ¨ UIæ ·å¼æ£€æŸ¥:")
            logger.info("  âœ… çº¯ç™½è‰²èƒŒæ™¯ (#FFFFFF)")
            logger.info("  âœ… ç°ä»£åŒ–æ»‘å—ç»„ä»¶")
            logger.info("  âœ… iOSé£æ ¼å¼€å…³ç»„ä»¶")
            logger.info("  âœ… åœ†è§’è¾¹æ¡†è®¾è®¡")
            logger.info("  âœ… è“è‰²ä¸»é¢˜è‰² (#0084FF)")
            logger.info("  âœ… æ¸å˜æŒ‰é’®æ•ˆæœ")
            logger.info("  âœ… ä¸­æ–‡å‚æ•°è¯´æ˜")

            # æµ‹è¯•æ¶ˆæ¯å‘é€ï¼ˆæ¨¡æ‹Ÿï¼‰
            def send_test_message():
                """å‘é€æµ‹è¯•æ¶ˆæ¯"""
                window.add_user_message("ä½ å¥½ï¼Œè¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯")
                logger.info("âœ… ç”¨æˆ·æ¶ˆæ¯æ·»åŠ æˆåŠŸ")

                # æ˜¾ç¤ºè¾“å…¥æŒ‡ç¤ºå™¨
                window.show_typing_indicator()
                logger.info("âœ… è¾“å…¥æŒ‡ç¤ºå™¨æ˜¾ç¤ºæˆåŠŸ")

                # æ¨¡æ‹Ÿæµå¼å“åº”
                QTimer.singleShot(1000, lambda: start_streaming())

            def start_streaming():
                """å¼€å§‹æµå¼å“åº”"""
                window.start_streaming_message()
                logger.info("âœ… å¼€å§‹æµå¼æ¶ˆæ¯")

                # æ¨¡æ‹Ÿæµå¼æ›´æ–°
                chunks = ["ä½ å¥½ï¼", "æˆ‘æ˜¯", "AIåŠ©æ‰‹ï¼Œ", "å¾ˆé«˜å…´", "ä¸ºæ‚¨", "æœåŠ¡ã€‚"]
                for i, chunk in enumerate(chunks):
                    QTimer.singleShot(200 * i, lambda c=chunk: update_stream(c))

                # å®Œæˆæµå¼å“åº”
                QTimer.singleShot(200 * len(chunks), finish_streaming)

            def update_stream(chunk):
                """æ›´æ–°æµå¼æ¶ˆæ¯"""
                window.update_streaming_message(chunk)
                logger.info(f"  ğŸ“ æµå¼æ›´æ–°: {chunk}")

            def finish_streaming():
                """å®Œæˆæµå¼å“åº”"""
                window.finish_streaming_message()
                logger.info("âœ… æµå¼æ¶ˆæ¯å®Œæˆ")

                # 3ç§’åå…³é—­çª—å£
                QTimer.singleShot(3000, close_window)

            def close_window():
                """å…³é—­çª—å£å¹¶é€€å‡º"""
                logger.info("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
                logger.info("  âœ… ç°ä»£åŒ–UIç•Œé¢åŠ è½½æˆåŠŸ")
                logger.info("  âœ… å‚æ•°é…ç½®é¢æ¿åŠŸèƒ½æ­£å¸¸")
                logger.info("  âœ… è°ƒè¯•ä¿¡æ¯æŸ¥çœ‹å™¨åŠŸèƒ½æ­£å¸¸")
                logger.info("  âœ… æµå¼æ¶ˆæ¯æ˜¾ç¤ºæ­£å¸¸")
                logger.info("  âœ… ä¸­æ–‡ç•Œé¢æ˜¾ç¤ºæ­£å¸¸")
                logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç°ä»£åŒ–UIå®ç°æˆåŠŸï¼")
                app.quit()

            # å»¶è¿Ÿå‘é€æµ‹è¯•æ¶ˆæ¯
            QTimer.singleShot(1000, send_test_message)

        else:
            logger.error("âŒ æ— æ³•è·å–å¯¹è¯çª—å£å®ä¾‹")
            app.quit()

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        app.quit()

    # è¿è¡Œåº”ç”¨
    return app.exec()

if __name__ == "__main__":
    sys.exit(test_modern_ui())